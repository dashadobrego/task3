{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import fasttext\n",
    "import bz2\n",
    "import string\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.python.keras import models, layers, optimizers\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import bz2\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dashadobrego/Downloads/Telegram Desktop'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "data = data.readlines()\n",
    "data = [x.decode('utf-8') for x in data]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial train dataset consists of 3'600'000 Amazon reviews. When trying to proceed the whole sample, my kernel died. It took several iterations to reveal that my computer works best (=just works) at 370'000. Important credits for this hint: Zamira M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = data[:370000]\n",
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame(sample_data)\n",
    "sample_data.to_csv(\"sample_train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__2', '__label__1'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised('sample_train.txt',label_prefix='__label__', thread=4, epoch = 10) \n",
    "#apply fasttext model to our data\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test data \n",
    "test = bz2.BZ2File(\"test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test = test[:40000] \n",
    "len(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do the creaning\n",
    "new = [w.replace('__label__2 ', '') for w in sample_test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]\n",
    "new = [w.replace('\\n', '') for w in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in sample_test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9013146720906343\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result is pretty high - 90,1%.\n",
    "Let's see how it goes on machine learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = 0  #clear reviews from \"label\" strings and create a column to store labels\n",
    "for i in range(0,len(train)):\n",
    "    review_text = train.iloc[i,0]\n",
    "    review_label = train.iloc[i,1]\n",
    "    if review_text.startswith('__label__2 '):\n",
    "        review_label = '__label__2'\n",
    "    if review_text.startswith('__label__1 '):\n",
    "        review_label = '__label__1' \n",
    "    train.iloc[i,1] = review_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index=False, sep=' ', header=True) #store dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test) #same for test set\n",
    "test['label'] = 0\n",
    "s=0\n",
    "for i in range(0,len(test)):\n",
    "    review_text = test.iloc[i,0]\n",
    "    review_label = test.iloc[i,1]\n",
    "    if review_text.startswith('__label__2 '):\n",
    "        review_label = '__label__2'\n",
    "    if review_text.startswith('__label__1 '):\n",
    "        review_label = '__label__1'\n",
    "    test.iloc[i,1] = review_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.to_csv(\"test.csv\", index=False, sep=' ', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>DVD Player crapped out after one year: I also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Incorrect Disc: I love the style of this, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>DVD menu select problems: I cannot scroll thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Unique Weird Orientalia from the 1930's: Exoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Not an \"ultimate guide\": Firstly,I enjoyed the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review\n",
       "0  __label__2  Great CD: My lovely Pat has one of the GREAT v...\n",
       "1  __label__2  One of the best game music soundtracks - for a...\n",
       "2  __label__1  Batteries died within a year ...: I bought thi...\n",
       "3  __label__2  works fine, but Maha Energy is better: Check o...\n",
       "4  __label__2  Great for the non-audiophile: Reviewed quite a...\n",
       "5  __label__1  DVD Player crapped out after one year: I also ...\n",
       "6  __label__1  Incorrect Disc: I love the style of this, but ...\n",
       "7  __label__1  DVD menu select problems: I cannot scroll thro...\n",
       "8  __label__2  Unique Weird Orientalia from the 1930's: Exoti...\n",
       "9  __label__1  Not an \"ultimate guide\": Firstly,I enjoyed the..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    20127\n",
       "__label__2    19873\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.sample(n = 40000, random_state=123).reset_index(drop=True) #take test sample of 40000\n",
    "test_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    185266\n",
       "__label__2    184734\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train.sample(n = 370000, random_state=123).reset_index(drop=True) #take train sample of 370000\n",
    "train_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = {'__label__2': 1, '__label__1': 0}\n",
    "train_sample['label'] = train_sample['label'].map(labels).astype(int) #turn label values to integers\n",
    "test_sample['label'] = test_sample['label'].map(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_data(data):  #function that lowercases the data and removes punctuation\n",
    "    data = data.str.lower() \n",
    "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sample['clean'] = process_data(train_sample['review'])\n",
    "test_sample['clean'] = process_data(test_sample['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this movie sucks: This movie supposedly about ...</td>\n",
       "      <td>this movie sucks this movie supposedly about m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Good Entertainment: This program a well edited...</td>\n",
       "      <td>good entertainment this program a well edited ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the job: This hamper does the job in my k...</td>\n",
       "      <td>does the job this hamper does the job in my ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Buffett Mails it In: Being a huge Buffett fan,...</td>\n",
       "      <td>buffett mails it in being a huge buffett fan i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sharp as a razor... almost.: Wow! My replaceme...</td>\n",
       "      <td>sharp as a razor almost wow my replacement is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Great Show BUT Too Much $$$$$$: Although I've ...</td>\n",
       "      <td>great show but too much  although ive been wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>HORRIBLE DONT BUY: My child got this Frog land...</td>\n",
       "      <td>horrible dont buy my child got this frog land ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>ok, purchased the wrong size: I bought this fo...</td>\n",
       "      <td>ok purchased the wrong size i bought this for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Guilt pleasure: I love Doris Day and really en...</td>\n",
       "      <td>guilt pleasure i love doris day and really enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't buy it-- READ THIS REVIEW: This movie is...</td>\n",
       "      <td>dont buy it read this review this movie is rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Bob's Red Mill Pumpkin Seeds, Raw, 24-Ounc...:...</td>\n",
       "      <td>bobs red mill pumpkin seeds raw 24ounc i have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Bizarro bad!: I was hopeful upon seeing the 5 ...</td>\n",
       "      <td>bizarro bad i was hopeful upon seeing the 5 ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Interesting But . . .: I found this to be an i...</td>\n",
       "      <td>interesting but    i found this to be an inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Take It For What It Is.: The new BSG series is...</td>\n",
       "      <td>take it for what it is the new bsg series is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't waste your money.: This headset is very ...</td>\n",
       "      <td>dont waste your money this headset is very poo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                             review  \\\n",
       "0       0  this movie sucks: This movie supposedly about ...   \n",
       "1       0  Good Entertainment: This program a well edited...   \n",
       "2       1  Does the job: This hamper does the job in my k...   \n",
       "3       0  Buffett Mails it In: Being a huge Buffett fan,...   \n",
       "4       1  Sharp as a razor... almost.: Wow! My replaceme...   \n",
       "5       0  Great Show BUT Too Much $$$$$$: Although I've ...   \n",
       "6       0  HORRIBLE DONT BUY: My child got this Frog land...   \n",
       "7       1  ok, purchased the wrong size: I bought this fo...   \n",
       "8       1  Guilt pleasure: I love Doris Day and really en...   \n",
       "9       0  Don't buy it-- READ THIS REVIEW: This movie is...   \n",
       "10      1  Bob's Red Mill Pumpkin Seeds, Raw, 24-Ounc...:...   \n",
       "11      0  Bizarro bad!: I was hopeful upon seeing the 5 ...   \n",
       "12      0  Interesting But . . .: I found this to be an i...   \n",
       "13      1  Take It For What It Is.: The new BSG series is...   \n",
       "14      0  Don't waste your money.: This headset is very ...   \n",
       "\n",
       "                                                clean  \n",
       "0   this movie sucks this movie supposedly about m...  \n",
       "1   good entertainment this program a well edited ...  \n",
       "2   does the job this hamper does the job in my ki...  \n",
       "3   buffett mails it in being a huge buffett fan i...  \n",
       "4   sharp as a razor almost wow my replacement is ...  \n",
       "5   great show but too much  although ive been wai...  \n",
       "6   horrible dont buy my child got this frog land ...  \n",
       "7   ok purchased the wrong size i bought this for ...  \n",
       "8   guilt pleasure i love doris day and really enj...  \n",
       "9   dont buy it read this review this movie is rea...  \n",
       "10  bobs red mill pumpkin seeds raw 24ounc i have ...  \n",
       "11  bizarro bad i was hopeful upon seeing the 5 ex...  \n",
       "12  interesting but    i found this to be an inter...  \n",
       "13  take it for what it is the new bsg series is a...  \n",
       "14  dont waste your money this headset is very poo...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_list = train_sample['clean'].values.tolist()\n",
    "test_list = test_sample['clean'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dashadobrego/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2500, stop_words=stopwords.words('english')) #use TF-IDF\n",
    "processed_train = vectorizer.fit_transform(train_list).toarray()\n",
    "processed_test = vectorizer.fit_transform(test_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = processed_train\n",
    "y_train = train_sample['label']\n",
    "X_test = processed_test\n",
    "y_test = test_sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.9, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=1234,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGboost = XGBClassifier(n_jobs = 1, random_state=1234, learning_rate=0.9)\n",
    "XGboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78904146, 0.21095854],\n",
       "       [0.54802406, 0.45197597],\n",
       "       [0.7388567 , 0.2611433 ],\n",
       "       ...,\n",
       "       [0.8975423 , 0.10245771],\n",
       "       [0.749894  , 0.250106  ],\n",
       "       [0.4283334 , 0.5716666 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGboost.predict_proba(X_test)\n",
    "\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "xgb_whole = xgb[:,1]>=0.4 #define cutoff\n",
    "xgb_int=xgb_whole.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5724893404514303\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, xgb_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROCAUC is very low compared to the fasttext results - only 58,22%. Could be possible to try different learning rates, however, I doubt that playing with LR can lead to 90%+ results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution is based on these ideas: https://www.kaggle.com/muonneutrino/sentiment-analysis-with-amazon-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_sample['review'], train_sample['label'], random_state=432, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_labels = test_sample['label']\n",
    "test_texts = test_sample['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 11000\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
    "val_texts = tokenizer.texts_to_sequences(val_texts)\n",
    "test_texts = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
    "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
    "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)\n",
    "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = np.asarray(val_labels)\n",
    "trains = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
    "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(embedded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool1D(5)(x)\n",
    "    x = layers.Conv1D(64, 5, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 296000 samples, validate on 74000 samples\n",
      "Epoch 1/2\n",
      "296000/296000 [==============================] - 214s 724us/sample - loss: 0.2505 - binary_accuracy: 0.8947 - val_loss: 0.1994 - val_binary_accuracy: 0.9202\n",
      "Epoch 2/2\n",
      "296000/296000 [==============================] - 203s 686us/sample - loss: 0.1706 - binary_accuracy: 0.9343 - val_loss: 0.1912 - val_binary_accuracy: 0.9246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a82bbd490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_texts, \n",
    "    trains, \n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(val_texts, vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.9769\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In conclusion, NN approach provided the best result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
